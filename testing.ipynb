{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = 80\n",
    "num_labels = 37\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  return dataset\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return np.sqrt(((predictions - labels) ** 2).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1, 80, 80) (1, 37)\n",
      "Validation set (20000, 80, 80) (20000, 37)\n",
      "Test set (20000, 80, 80) (20000, 37)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'galaxies.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = (save['train_dataset'])[0:1]\n",
    "  train_labels = (save['train_labels'])[0:1]\n",
    "  valid_dataset = (save['valid_dataset'])\n",
    "  valid_labels = (save['valid_labels'])\n",
    "  test_dataset = (save['test_dataset'])\n",
    "  test_labels = (save['test_labels'])\n",
    "\n",
    "  del save  # hint to help gc free up memory\n",
    "    \n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1, 80, 80, 1) (1, 37)\n",
      "Validation set (20000, 80, 80, 1) (20000, 37)\n",
      "Test set (20000, 80, 80, 1) (20000, 37)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = reformat(train_dataset)\n",
    "valid_dataset = reformat(valid_dataset)\n",
    "test_dataset = reformat(test_dataset)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103719"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "#   MODEL 5\n",
    "batch_size = 128 #109\n",
    "patch_size = 5\n",
    "depth = 32 #32, 16\n",
    "num_hidden = 64 #100\n",
    "num_hidden2 = 64 #37\n",
    "beta = 0.0002#0.0002\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=sqrt(2.0/(image_size // 4 * image_size // 4 * depth * num_hidden))))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  print(str(num_hidden))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_hidden2], stddev=sqrt(2.0/(num_hidden * num_hidden2))))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))\n",
    "  print(str(num_hidden2))\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden2, num_labels], stddev=sqrt(2.0/(num_hidden2 * num_labels))))\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer1_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer2_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden2, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss1 = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(logits, tf_train_labels))))\n",
    "  loss = loss1 + beta * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer5_weights))\n",
    "    \n",
    " # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  #learning_rate = tf.train.exponential_decay(0.3, global_step, 5000 ,0.96, staircase = True) #5000\n",
    "  learning_rate = tf.Variable(0.3)\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "   \n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  def prediction(logits):\n",
    "    pred1 = tf.nn.softmax(logits[:,0:3])\n",
    "    pred2 = tf.nn.relu(logits[:,3:num_labels])\n",
    "    pred = tf.concat([pred1, pred2],1)\n",
    "    return pred\n",
    "  train_prediction1 = prediction(logits)\n",
    "   #drop out some of the predictions\n",
    "  train_prediction = tf.nn.dropout(train_prediction1,0.5)\n",
    "  \n",
    "\n",
    "  valid_prediction =prediction(model(valid_dataset))\n",
    "  test_prediction = prediction(model(test_dataset))\n",
    "\n",
    "  tf.add_to_collection('vars',  layer1_weights)\n",
    "  tf.add_to_collection('vars',  layer2_weights)\n",
    "  tf.add_to_collection('vars',  layer3_weights)\n",
    "  tf.add_to_collection('vars',  layer4_weights)\n",
    "  tf.add_to_collection('vars',  layer5_weights)\n",
    "  tf.add_to_collection('vars',  layer1_biases)\n",
    "  tf.add_to_collection('vars',  layer2_biases)\n",
    "  tf.add_to_collection('vars',  layer3_biases)\n",
    "  tf.add_to_collection('vars',  layer4_biases)\n",
    "  tf.add_to_collection('vars',  layer5_biases)\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "Test accuracy: 0.112352\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "acc = 0\n",
    "t = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    saver.restore(session, './my-model5.ckpt')\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    for i in range(0,20): \n",
    "        a = accuracy((prediction(model(valid_dataset[i*1000:(i+1)*1000]))).eval(), valid_labels[i*1000:(i+1)*1000])\n",
    "        acc = acc + a\n",
    "        t.append(a)\n",
    "    plt.plot(range(0,20), t, 'r')\n",
    "    plt.axis([0, 20, 0, 0.2])\n",
    "    acc = acc / 20\n",
    "    print('Test accuracy: %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# MODEL 6\n",
    "batch_size = 128 #109\n",
    "patch_size = 5\n",
    "depth = 32 #32, 16\n",
    "num_hidden = 100\n",
    "num_hidden2 = 37\n",
    "beta = 0.0002#0.0002\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=sqrt(2.0/(image_size // 4 * image_size // 4 * depth * num_hidden))))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  print(str(num_hidden))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_hidden2], stddev=sqrt(2.0/(num_hidden * num_hidden2))))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))\n",
    "  print(str(num_hidden2))\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden2, num_labels], stddev=sqrt(2.0/(num_hidden2 * num_labels))))\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer1_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer2_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden2, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss1 = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(logits, tf_train_labels))))\n",
    "  loss = loss1 + beta * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer5_weights))\n",
    "    \n",
    " # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  #learning_rate = tf.train.exponential_decay(0.3, global_step, 5000 ,0.96, staircase = True) #5000\n",
    "  learning_rate = tf.Variable(0.3)\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "   \n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  def prediction(logits):\n",
    "    pred1 = tf.nn.softmax(logits[:,0:3])\n",
    "    pred2 = tf.nn.relu(logits[:,3:num_labels])\n",
    "    pred = tf.concat([pred1, pred2],1)\n",
    "    return pred\n",
    "  train_prediction1 = prediction(logits)\n",
    "    \n",
    "   #drop out some of the predictions\n",
    "  train_prediction = tf.nn.dropout(train_prediction1,0.5)\n",
    "  \n",
    "\n",
    "  valid_prediction =prediction(model(valid_dataset))\n",
    "  test_prediction = prediction(model(test_dataset))\n",
    "\n",
    "  tf.add_to_collection('vars',  layer1_weights)\n",
    "  tf.add_to_collection('vars',  layer2_weights)\n",
    "  tf.add_to_collection('vars',  layer3_weights)\n",
    "  tf.add_to_collection('vars',  layer4_weights)\n",
    "  tf.add_to_collection('vars',  layer5_weights)\n",
    "  tf.add_to_collection('vars',  layer1_biases)\n",
    "  tf.add_to_collection('vars',  layer2_biases)\n",
    "  tf.add_to_collection('vars',  layer3_biases)\n",
    "  tf.add_to_collection('vars',  layer4_biases)\n",
    "  tf.add_to_collection('vars',  layer5_biases)\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "Test accuracy: 0.123348\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "acc = 0\n",
    "t = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    saver.restore(session, './my-model6.ckpt')\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    for i in range(0,20): \n",
    "        a = accuracy((prediction(model(test_dataset[i*1000:(i+1)*1000]))).eval(), test_labels[i*1000:(i+1)*1000])\n",
    "        acc = acc + a\n",
    "        t.append(a)\n",
    "    plt.plot(range(0,20), t, 'b')\n",
    "    plt.axis([0, 20, 0, 0.2])\n",
    "    acc = acc / 20\n",
    "    print('Test accuracy: %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "#   MODEL 7\n",
    "batch_size = 109\n",
    "patch_size = 5\n",
    "depth = 32 #32, 16\n",
    "num_hidden = 100\n",
    "num_hidden2 = 37\n",
    "beta = 0.0002#0.0002\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=sqrt(2.0/(image_size // 4 * image_size // 4 * depth * num_hidden))))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  print(str(num_hidden))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_hidden2], stddev=sqrt(2.0/(num_hidden * num_hidden2))))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))\n",
    "  print(str(num_hidden2))\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden2, num_labels], stddev=sqrt(2.0/(num_hidden2 * num_labels))))\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer1_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer2_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden2, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss1 = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(logits, tf_train_labels))))\n",
    "  loss = loss1 + beta * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer5_weights))\n",
    "    \n",
    " # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  #learning_rate = tf.train.exponential_decay(0.3, global_step, 5000 ,0.96, staircase = True) #5000\n",
    "  learning_rate = tf.Variable(0.3)\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "   \n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  def prediction(logits):\n",
    "    pred1 = tf.nn.softmax(logits[:,0:3])\n",
    "    pred2 = tf.nn.relu(logits[:,3:num_labels])\n",
    "    pred = tf.concat([pred1, pred2],1)\n",
    "    return pred\n",
    "  train_prediction1 = prediction(logits)\n",
    "   #drop out some of the predictions\n",
    "  train_prediction = tf.nn.dropout(train_prediction1,0.5)\n",
    "  \n",
    "\n",
    "  valid_prediction =prediction(model(valid_dataset))\n",
    "  test_prediction = prediction(model(test_dataset))\n",
    "\n",
    "  tf.add_to_collection('vars',  layer1_weights)\n",
    "  tf.add_to_collection('vars',  layer2_weights)\n",
    "  tf.add_to_collection('vars',  layer3_weights)\n",
    "  tf.add_to_collection('vars',  layer4_weights)\n",
    "  tf.add_to_collection('vars',  layer5_weights)\n",
    "  tf.add_to_collection('vars',  layer1_biases)\n",
    "  tf.add_to_collection('vars',  layer2_biases)\n",
    "  tf.add_to_collection('vars',  layer3_biases)\n",
    "  tf.add_to_collection('vars',  layer4_biases)\n",
    "  tf.add_to_collection('vars',  layer5_biases)\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "Test accuracy: 0.114564\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "acc = 0\n",
    "t = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    saver.restore(session, './my-model4.ckpt')\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    for i in range(0,20): \n",
    "        a = accuracy((prediction(model(test_dataset[i*1000:(i+1)*1000]))).eval(), test_labels[i*1000:(i+1)*1000])\n",
    "        acc = acc + a\n",
    "        t.append(a)\n",
    "    plt.plot(range(0,20), t, 'g')\n",
    "    plt.axis([0, 20, 0, 0.2])\n",
    "    acc = acc / 20\n",
    "    print('Test accuracy: %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "#     MODEL 3\n",
    "batch_size = 109\n",
    "patch_size = 5\n",
    "depth = 32 #32, 16\n",
    "num_hidden = 100\n",
    "num_hidden2 = 37\n",
    "beta = 0.0002\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=sqrt(2.0/(image_size // 4 * image_size // 4 * depth * num_hidden))))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  print(str(num_hidden))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_hidden2], stddev=sqrt(2.0/(num_hidden * num_hidden2))))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))\n",
    "  print(str(num_hidden2))\n",
    "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden2, num_labels], stddev=sqrt(2.0/(num_hidden2 * num_labels))))\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "\n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer1_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(conv + layer2_biases)\n",
    "    hidden =  tf.nn.max_pool(hidden1, [1,2,2,1], [1,2,2,1],padding='SAME')\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden2, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss1 = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(logits, tf_train_labels))))\n",
    "  loss = loss1 + beta * (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer4_weights) + tf.nn.l2_loss(layer5_weights))\n",
    "    \n",
    " # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.3, global_step, 5000 ,0.96, staircase = True) #5000\n",
    "  #learning_rate = tf.Variable(0.3)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "   \n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  def prediction(logits):\n",
    "    pred1 = tf.nn.softmax(logits[:,0:3])\n",
    "    pred2 = tf.nn.relu(logits[:,3:num_labels])\n",
    "    pred = tf.concat([pred1, pred2],1)\n",
    "    return pred\n",
    "  train_prediction1 = prediction(logits)\n",
    "   #drop out some of the predictions\n",
    "  train_prediction = tf.nn.dropout(train_prediction1,0.5)\n",
    "  \n",
    "\n",
    "  valid_prediction =prediction(model(valid_dataset))\n",
    "  test_prediction = prediction(model(test_dataset))\n",
    "\n",
    "  tf.add_to_collection('vars',  layer1_weights)\n",
    "  tf.add_to_collection('vars',  layer2_weights)\n",
    "  tf.add_to_collection('vars',  layer3_weights)\n",
    "  tf.add_to_collection('vars',  layer4_weights)\n",
    "  tf.add_to_collection('vars',  layer5_weights)\n",
    "  tf.add_to_collection('vars',  layer1_biases)\n",
    "  tf.add_to_collection('vars',  layer2_biases)\n",
    "  tf.add_to_collection('vars',  layer3_biases)\n",
    "  tf.add_to_collection('vars',  layer4_biases)\n",
    "  tf.add_to_collection('vars',  layer5_biases)\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "Test accuracy: 0.171488\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "acc = 0\n",
    "t = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    saver.restore(session, './my-model3.ckpt')\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    for i in range(0,20): \n",
    "        a = accuracy((prediction(model(test_dataset[i*1000:(i+1)*1000]))).eval(), test_labels[i*1000:(i+1)*1000])\n",
    "        acc = acc + a\n",
    "        t.append(a)\n",
    "    plt.plot(range(0,20), t, 'y')\n",
    "    plt.axis([0, 20, 0, 0.2])\n",
    "    acc = acc / 20\n",
    "    print('Test accuracy: %f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhYiIxFJYiIhILIWFiIjE+t8T44F8pXeVuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a4af354c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
